{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyMDh+RuJu7t1AzeAtK+YXcM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jHgxVl0mPFU-"},"outputs":[],"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n","from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Embedding\n","from tensorflow.keras.layers import SpatialDropout1D, Conv1D, Bidirectional, LSTM, Dense, Input, Dropout, GlobalMaxPooling1D\n","from keras.models import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n"],"metadata":{"id":"4cqb28m7QSCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(r'/content/gdrive/MyDrive/Final_Dataset.tsv',delimiter='\\t')"],"metadata":{"id":"N9eUQc5oQSNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.head())"],"metadata":{"id":"GCMC0FCYQSRH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["positive_reviews = df[df['Label'] > 3]\n","\n","\n","positive_reviews"],"metadata":{"id":"dKXoa2fSaxBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["negative_reviews = df[df['Label'] < 3]\n","negative_reviews\n"],"metadata":{"id":"l8Swi1KyaxI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.concat([positive_reviews, negative_reviews], ignore_index = True)\n","data.head()"],"metadata":{"id":"oHiNeLQraxMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train,df_test=train_test_split(data,test_size=0.3)"],"metadata":{"id":"1gSTAOZPQSZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_VOCAB_SIZE=250000\n","tokenizer=Tokenizer(num_words=MAX_VOCAB_SIZE,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n","tokenizer.fit_on_texts(df_train['Text'])\n","sequences_train = tokenizer.texts_to_sequences(df_train['Text'])\n","sequences_test = tokenizer.texts_to_sequences(df_test['Text'])"],"metadata":{"id":"GNepWjaXQSdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2idx=tokenizer.word_index\n","V=len(word2idx)\n","V"],"metadata":{"id":"ubE5R3-IQSgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train=pad_sequences(sequences_train)\n","T=data_train.shape[1]\n","T"],"metadata":{"id":"2ROKyLdxQSvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_test=pad_sequences(sequences_test)\n"],"metadata":{"id":"xzaTnmSWQSy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gensim\n","Embedding_dim=300\n","file='/content/gdrive/MyDrive/tweet_cbow_300/tweets_cbow_300'\n","!iconv -f ISO-8859-1 -t UTF-8 /content/gdrive/MyDrive/tweet_cbow_300/tweets_cbow_300> /content/gdrive/MyDrive/tweets_utf8.txt\n","file_utf8 = '/content/gdrive/MyDrive/tweets_utf8.txt'\n","# Initialize an empty embeddings index dictionary\n","EMBEDDINGS_MATRIX = np.zeros ((V+1, Embedding_dim)) #EMBEDDINGS MATRIX-11\n","model = gensim.models.Word2Vec.load(file)\n","for word, i in word2idx.items():\n","  embedding_vector = None\n","  if word != \"<OOV>\":\n","    if word in model.wv:\n","      embedding_vector = model.wv[word]\n","EMBEDDINGS_MATRIX[i] = embedding_vector\n"],"metadata":{"id":"NcxY63vWQoPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EMBEDDINGS_MATRIX = np.nan_to_num(EMBEDDINGS_MATRIX)"],"metadata":{"id":"DSQOSA4OQoaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convlution with BI LSTM\n","model = Sequential()\n","embedding_layer = Embedding(V+1, \n","                            300, \n","                            weights = [EMBEDDINGS_MATRIX], \n","                            input_length = T , \n","                            trainable=False)\n","model.add(embedding_layer)\n","model.add(Conv1D(filters=300, kernel_size=2, activation='relu'))\n","model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.2))\n","model.add(Dense(3, activation='softmax'))\n"],"metadata":{"id":"Odp2jsZ8QoeT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer = Adam(learning_rate=0.0001), \n","              loss=SparseCategoricalCrossentropy(from_logits=True),\n","              metrics = ['accuracy'])\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","print(model.summary())"],"metadata":{"id":"f4ze3F5-hRR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(data_train, df_train['Label'], batch_size = 128, epochs=5, validation_data=(data_test,df_test['Label']),verbose=1, callbacks=[es])\n","#history = model.fit(data_train, df_train['Label'], validation_split=0.15, batch_size = 124, epochs=5, verbose=1, callbacks=[es])\n","\n"],"metadata":{"id":"INkQA5V_j0bY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_train = history.history['loss']\n","loss_val = history.history['val_loss']\n","epochs = range(1,21)\n"],"metadata":{"id":"2mvST8XAj0hE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(epochs, loss_train, 'g', label='Training loss')\n","plt.plot(epochs, loss_val, 'b', label='validation loss')\n","plt.title('Training and Validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"BVLKRC37JUwL"},"execution_count":null,"outputs":[]}]}